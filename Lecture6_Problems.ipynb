{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d61d4f1",
   "metadata": {},
   "source": [
    "# 인공신경망의 Back-propagation 을 해봅시다\n",
    "\n",
    "이번 과제의 목표는 Back-propagation 을 계산하고 이를 torch의 자동 미분과 비교하여 맞는지 확인하는 것입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419746f3",
   "metadata": {},
   "source": [
    "## 1) 필수 라이브러리와 함수를 불러 옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f4cdaf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "118d75b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU_func(outputs):\n",
    "    zero_tensor = torch.zeros(outputs.size())\n",
    "    final_outputs = torch.maximum(outputs,zero_tensor)\n",
    "\n",
    "    return final_outputs\n",
    "\n",
    "def softmax(outputs):\n",
    "    numerator = torch.exp(outputs - torch.max(outputs,axis=1)[0].view(-1,1))\n",
    "    denominator = torch.sum(numerator, axis=1).view(-1,1)\n",
    "    softmax = numerator/denominator\n",
    "    \n",
    "    return softmax\n",
    "\n",
    "def cross_entropy(outputs, labels):\n",
    "    return torch.sum(-1*labels*torch.log(outputs),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76bc787",
   "metadata": {},
   "source": [
    "## 2) 인공신경망 계산을 합니다. \n",
    "\n",
    "입력은 [4,1], Label은 [0,1], W_0 은 $\\pmatrix{1,-2 \\\\ 2,5}$, W_1은  $\\pmatrix{3,-3 \\\\ -1,1}$ 로 주어졌을 때\n",
    "\n",
    "각 단계를 h, L, O, s, l 를 각각 역치 전 값, 히든 레이어 값, 출력값, 소프트맥스 후, loss로 하여 계산합니다.\n",
    "각 값은 torch.tensor 클래스의 객체로 만들어 자동미분이 가능하게 만드세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "65948804",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = torch.tensor([4.,1.], requires_grad = True)\n",
    "label = torch.tensor([0.,1.], requires_grad = True)\n",
    "W_0 = torch.tensor([[1.,-2.],[2.,5.]], requires_grad = True)\n",
    "W_1 = torch.tensor([[3.,-3.],[-1.,1.]], requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e6298740",
   "metadata": {},
   "outputs": [],
   "source": [
    "h =  torch.matmul(W_0,I)\n",
    "L =  ReLU_func(h)\n",
    "O =  torch.matmul(W_1, L)\n",
    "s =  softmax(O.reshape(1,-1))\n",
    "l =  cross_entropy(s.unsqueeze(0), label.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b7f76753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.]], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c4ddbbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "l.mean().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bce7932",
   "metadata": {},
   "source": [
    "## 3) $\\nabla_{W_0}l$ 계산하기\n",
    "\n",
    "위에서 주어진 h, L, O, s, l을 이용하여 $\\nabla_{W_0}l$를 계산해봅시다. \n",
    "\n",
    "numpy를 이용하여 계산하세요!\n",
    "\n",
    "참고로 \n",
    "\n",
    " $$\\nabla_s l = \\pmatrix{-\\frac{label_0}{s_0}, -\\frac{label_1}{s_1} } $$\n",
    " $$ \\nabla_o s = \\pmatrix{s_0(1-s_0), -s_0s_1 \\\\ -s_1s_0, s_1(1-s_1) }$$\n",
    " $$ \\nabla_{w_1} o = \\pmatrix{L_0,0,L_1,0 \\\\ 0, L_0, 0, L_1 }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5ee0db13",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [93]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m s_l\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m-\u001b[39mlabel[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m/\u001b[39m \u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m-\u001b[39mlabel[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m/\u001b[39m s[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()])\n\u001b[1;32m      2\u001b[0m o_s\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([s[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39ms[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;241m-\u001b[39ms[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39ms[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m-\u001b[39ms[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39ms[\u001b[38;5;241m0\u001b[39m], s[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39ms[\u001b[38;5;241m1\u001b[39m])])\n\u001b[1;32m      3\u001b[0m w1_o\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[L[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem(), \u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m0\u001b[39m, L[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()]])\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "s_l= np.array([-label[0].item() / s[0].item(), -label[1].item() / s[1].item()])\n",
    "o_s= np.array([s[0]*(1-s[0]), -s[0]*s[1]-s[1]*s[0], s[1]*(1-s[1])])\n",
    "w1_o= np.array([[L[0].item(), 0], [0, L[1].item()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "adae2c20",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'o_s' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [94]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m w1_l \u001b[38;5;241m=\u001b[39m  W_1\u001b[38;5;241m.\u001b[39mt()\u001b[38;5;241m.\u001b[39mmatmul(torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[43mo_s\u001b[49m])\u001b[38;5;241m.\u001b[39mt() \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([s_l]))\u001b[38;5;241m.\u001b[39mt()\u001b[38;5;66;03m# 채워넣으시오\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(w1_l)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'o_s' is not defined"
     ]
    }
   ],
   "source": [
    "w1_l =  W_1.t().matmul(torch.tensor([o_s]).t() * torch.tensor([s_l])).t()# 채워넣으시오\n",
    "print(w1_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e15da6d",
   "metadata": {},
   "source": [
    "자동 미분 결과와 비교해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7db40016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.7811e-20,  5.0577e-19],\n",
       "        [-7.7811e-20, -5.0577e-19]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_1.grad # 채워넣으시오"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fb7993",
   "metadata": {},
   "source": [
    "자동 미분 결과와 비교해보고 차이점이 무엇인지 그리고 왜 그런 결과가 생겼는지 서술하시오."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08a922a",
   "metadata": {},
   "source": [
    "정답) numpy로 계산한 결과는 벡터와 자동미분한 결과는 매트릭스로 결과가 나왔다. numpy로 계산한 결과는 w1_o의 정의에 따라 벡터로 출력되며, 자동 미분은 입력의 차원으로 계산되기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637ccfab",
   "metadata": {},
   "source": [
    "## 4) $\\nabla_{w_0} l $ 계산하기\n",
    "\n",
    "위에서 주어진 h, L, O, s, l을 이용하여 $\\nabla_{W_0}l$를 계산해봅시다. \n",
    "\n",
    "numpy를 이용하여 계산하세요!\n",
    "\n",
    "참고로 \n",
    "\n",
    " $$\\nabla_L o = W_1^T $$\n",
    " $$ \\nabla_h L = \\pmatrix{1 or 0, 0 \\\\ 0, 1 or 0 }$$\n",
    " $$ \\nabla_{w_0} h = \\pmatrix{I_0,0,I_1,0 \\\\ 0, I_0, 0, I_1 }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ca368948",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [96]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m L_o \u001b[38;5;241m=\u001b[39m  W_1\u001b[38;5;241m.\u001b[39mt()\u001b[38;5;66;03m# 채워넣으시오\u001b[39;00m\n\u001b[1;32m      2\u001b[0m h_L \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]]) \u001b[38;5;28;01mif\u001b[39;00m h[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m0\u001b[39m], [\u001b[38;5;241m0\u001b[39m]]) \u001b[38;5;66;03m# 채워넣으시오) \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m w0_h \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mI\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mI\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/_tensor.py:732\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 732\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "L_o =  W_1.t()# 채워넣으시오\n",
    "h_L = np.array([[1, 0], [0, 1]]) if h[0] > 0 else np.array([[0], [0]]) # 채워넣으시오) \n",
    "w0_h = np.array([I[0], 0, I[1], 0]).reshape(2,2).T # 채워넣으시오) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0f222922",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [97]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m w0_l \u001b[38;5;241m=\u001b[39m  \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mL\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mT\u001b[38;5;66;03m# 채워넣으시오\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(w0_l)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.10/site-packages/torch/_tensor.py:732\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    730\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 732\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "w0_l =  np.array([L[0], 0, 0, L[1]]).reshape(2,2).T# 채워넣으시오\n",
    "print(w0_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72876cd3",
   "metadata": {},
   "source": [
    "자동미분과 비교해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fa8a52d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.2249e-19,  1.5562e-19],\n",
       "        [-6.2249e-19, -1.5562e-19]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_0.grad # 채워넣으시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a30266da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이서영 2020125046\n"
     ]
    }
   ],
   "source": [
    "print(\"이서영 2020125046\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2430d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
